{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch import unsqueeze, where, matmul, sum, repeat_interleave, sqrt, topk, flip, index_select, cat\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataprocess.cic_ids_2017 import CIC_IDS_2107_DataLoader\n",
    "# from net.linear import linear_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_with_distance(src, dis, k):\n",
    "    \"\"\"\n",
    "    find for every data in src its k-nearest neighbor from dis with index and distance \n",
    "    params:\n",
    "        src: (N, C) \n",
    "        dis: (M, C)\n",
    "        k: numbers to select from dis\n",
    "    return:\n",
    "        indices: (N, k)\n",
    "        distance: (N, k) \n",
    "    \"\"\"\n",
    "    N, _ =src.shape\n",
    "    M, _ = dis.shape\n",
    "    src_sqare = repeat_interleave(sum(src ** 2, -1).reshape(N,1), M, 1, output_size=M) # (N, M)\n",
    "    dis_sqare = repeat_interleave(sum(dis ** 2, -1).reshape(1,M), N, 0, output_size=N) # (N, M)\n",
    "    src_ids = matmul(src, dis.permute(1,0)) # (N, M)\n",
    "    distance = src_sqare + dis_sqare - 2 * src_ids\n",
    "    distance, indices = topk(distance, k, 1) # (N, k)\n",
    "    distance = sqrt(distance)\n",
    "\n",
    "    return flip(indices,dims=[1]), flip(distance, dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonconformity_measure(train_index, train_distance, train_label):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        train_index: (N, k)\n",
    "        train_distance: (N, k)\n",
    "        label: (M, L)\n",
    "    return:\n",
    "        nonconformity: (N, L) \n",
    "    \"\"\"\n",
    "    N, k = train_distance.shape\n",
    "    _, L = train_label.shape\n",
    "    # train_distance = repeat_interleave(train_distance.reshape(N, 1, k), L, 1, output_size=L) # (N, L, k)\n",
    "    train_distance = train_distance.reshape(N, 1, k)\n",
    "    labels = train_label[train_index] # (N, k, L)\n",
    "    labels = ~labels\n",
    "    nonconformity = matmul(train_distance, labels.float()) # (N, 1, L)\n",
    "    nonconformity = nonconformity.reshape(N, L)\n",
    "    nonconformity = nonconformity ** (-1)\n",
    "    return nonconformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonconformity_measure_cali(cali_label, train_index, train_distance, train_label):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        cali_label: (N, L)\n",
    "        train_index: (N, k)\n",
    "        train_distance: (N, k)\n",
    "        label: (M, L)\n",
    "    return:\n",
    "        nonconformity: (N, ) \n",
    "    \"\"\"\n",
    "    N, k = train_distance.shape\n",
    "    _, L = train_label.shape\n",
    "    # train_distance = repeat_interleave(train_distance.reshape(N, 1, k), L, 1, output_size=L) # (N, L, k)\n",
    "    train_distance = train_distance.reshape(N, 1, k)\n",
    "    labels = train_label[train_index] # (N, k, L)\n",
    "    labels = ~labels\n",
    "    nonconformity = matmul(train_distance, labels.float()) # (N, 1, L)\n",
    "    nonconformity = nonconformity.reshape(N, L)\n",
    "    nonconformity = nonconformity ** (-1)\n",
    "    nonconformity = sum(nonconformity * cali_label, 1) # (N, )\n",
    "    return nonconformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN(nn.Module):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        input_channel:\n",
    "        output_channel:\n",
    "    inputs:\n",
    "        feature: (M, C)\n",
    "        train_feature: (N, C)\n",
    "        train_label: (N, L), one-hot code\n",
    "    return:\n",
    "        nonconformity: (M, L)\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        super(kNN, self).__init__()\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, feature, train_feature, train_label):\n",
    "        index, distance = topk_with_distance(feature, train_feature, self.k) # (M, k), (M, k)\n",
    "        nonconformity = nonconformity_measure(index, distance, train_label) # (M, L)\n",
    "        return nonconformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_3(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(linear_3, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_channel, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_channel)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "\n",
    "        self.drop = nn.Dropout()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x1 = self.fc1(input_data)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.drop(x1)\n",
    "        x2 = self.fc2(x1)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = self.drop(x2)\n",
    "        x3 = self.fc3(x2)\n",
    "        x3 = self.softmax(x3)\n",
    "        return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DkNN_linear_3(nn.Module):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        input_channel: int\n",
    "        output_channel: int\n",
    "        k:int\n",
    "        knn_weight: tensor, same length with layers of basic net\n",
    "    input:\n",
    "        test_input: (N, C)\n",
    "        train_feature: (M, C)\n",
    "        train_label: (M, L)\n",
    "        cali_nonconformity: (G,)\n",
    "    output:\n",
    "        logits: (N, L)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channel, output_channel, k, knn_weight):\n",
    "        super(DkNN_linear_3, self).__init__()\n",
    "        self.bone_net = linear_3(input_channel, output_channel)\n",
    "        self.knn1 = kNN(k)\n",
    "        self.knn2 = kNN(k)\n",
    "        self.knn3 = kNN(k)\n",
    "\n",
    "        self.drop = nn.Dropout()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.nonconformity_weight = knn_weight\n",
    "\n",
    "    def forward(self, test_input, train_feature, train_label, cali_nonconformity):\n",
    "        N, _ = test_input.shape\n",
    "        _, L = train_label.shape\n",
    "        G, = cali_nonconformity.shape\n",
    "        with torch.no_grad():\n",
    "            x1, x2, x3 = self.bone_net(test_input)\n",
    "\n",
    "            # knn part\n",
    "            nonconformity_1 = self.knn1(x1, train_feature, train_label).reshape(N, 1, L)\n",
    "            nonconformity_2 = self.knn2(x2, train_feature, train_label).reshape(N, 1, L)\n",
    "            nonconformity_3 = self.knn3(x3, train_feature, train_label).reshape(N, 1, L)\n",
    "            \n",
    "            nonconfotmity = cat((nonconformity_1, nonconformity_2, nonconformity_3), 1) # (N, 3, L)\n",
    "            nonconformity_weight = self.nonconformity_weight.repeat(N).reshape(N,3,1)\n",
    "            nonconformity_weight = repeat_interleave(nonconformity_weight, L, dim=2, output_size=L)\n",
    "\n",
    "            weighted_nonconformity = sum(nonconfotmity * nonconformity_weight, dim=1).reshape(N, L, 1)\n",
    "            _logits = repeat_interleave(weighted_nonconformity, G, dim=2, output_size=G) > cali_nonconformity #(N, L, G)\n",
    "            logits = sum(_logits.int(), dim=2) / G # (N, L)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['bone_net.fc1.weight', 'bone_net.fc1.bias', 'bone_net.fc2.weight', 'bone_net.fc2.bias', 'bone_net.fc3.weight', 'bone_net.fc3.bias'], unexpected_keys=['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dknn_weight = torch.Tensor([0.3, 0.4, 0.3])\n",
    "DkNN_net = DkNN_linear_3(85, 9, 200, dknn_weight)\n",
    "ckpt_file = 'history/linear_3/test_cic_Ids2017/checkpoint/6_13/ckpt_best_99.pth'\n",
    "checkpoint = torch.load(ckpt_file)\n",
    "DkNN_net.load_state_dict(checkpoint['net'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_dataset = CIC_IDS_2107_DataLoader('E:/DkNN/data/CIC-IDS2017', batch_size=1, mode='Cali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "log_directory:  log/exp/linear_3/test3_cic_ids2017/6_15/\n",
      "ckpt_directory:  history/linear_3/test3_cic_ids2017/checkpoint/6_15/\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "t = time.localtime()\n",
    "year, month, day = t.tm_year, t.tm_mon, t.tm_mday\n",
    "\n",
    "net = input('input the name of net to train: ')\n",
    "mode = input('input the tag about the training: ')\n",
    "if mode == '':\n",
    "    mode = 'no_tag'\n",
    "\n",
    "log_directory = f\"log/exp/{net}/{mode}/{month}_{day}/\"\n",
    "ckpt_directory = f\"history/{net}/{mode}/checkpoint/{month}_{day}/\"\n",
    "if not os.path.isdir(log_directory):\n",
    "    os.makedirs(log_directory)\n",
    "if not os.path.isdir(ckpt_directory):\n",
    "    os.makedirs(ckpt_directory)\n",
    "print('log_directory: ', log_directory)\n",
    "print('ckpt_directory: ', ckpt_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 85\n"
     ]
    }
   ],
   "source": [
    "# for cic_ids2017\n",
    "batch_size = 256\n",
    "dataset = CIC_IDS_2107_DataLoader('E:\\DataSets\\CIC-IDS2016', batch_size, mode='Train')\n",
    "data_labels = dataset.data.label_category.keys()\n",
    "class_num = len(data_labels)\n",
    "feature_length = dataset.data.feature_length\n",
    "print(class_num, feature_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer1 = SummaryWriter(log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = linear_3(feature_length, class_num).to(device)\n",
    "\n",
    "epoch = 100\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(0, epoch):\n",
    "    running_loss = 0.0\n",
    "    for step, (x, y) in enumerate(dataset):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        _, _, y_pred = net(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # visualize loss\n",
    "        running_loss += loss.item() / batch_size\n",
    "    # ...log the running loss\n",
    "    writer1.add_scalar('training loss', running_loss, t)\n",
    "    scheduler.step()\n",
    "    if t % 10 == 9:\n",
    "        checkpoint = {\"net\": net.state_dict(), 'optimizer':optimizer.state_dict(), \"epoch\": t}\n",
    "        torch.save(checkpoint,  ckpt_directory + 'ckpt_best_%s.pth' %(str(t)))\n",
    "writer1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(dataset):\n",
    "    if step == 0:\n",
    "        cali_data = x\n",
    "        cali_label = y\n",
    "    else:\n",
    "        cali_data = cat((cali_data, x))\n",
    "        cali_label = cat((cali_label, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[18, 13], [10, 13], [0, 3]], [[3, 5], [8, 13], [21, 15]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,32,size=(2,3,2)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[[1, 0], [1, 1], [0, 0]], [[1, 1], [0, 0], [0, 1]]]).bool()\n",
    "b = torch.Tensor([7,15]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 0],\n",
      "        [2, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "c = sum(a.int(), 2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = 20000, 5000\n",
    "nonconformity = torch.Tensor(np.random.random(size=(N,))*3.4E+38)\n",
    "standard_nonconformity = torch.Tensor(np.random.random(size=(M,))*3.4E+38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 5000])\n"
     ]
    }
   ],
   "source": [
    "nonconformity = unsqueeze(nonconformity, -1)\n",
    "nonconformity = nonconformity.repeat(1, M)\n",
    "print(nonconformity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 5000])\n"
     ]
    }
   ],
   "source": [
    "result = nonconformity - standard_nonconformity\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_array = torch.ones(result.shape)\n",
    "zeros_array = torch.zeros(result.shape)\n",
    "_result = where(result < 0,ones_array,zeros_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000])\n"
     ]
    }
   ],
   "source": [
    "result = _result.sum(-1, keepdim=False)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5904, 0.8680, 0.3888, 0.2612, 0.4950, 0.0360, 0.8210, 0.2072, 0.8244,\n",
      "        0.3100, 0.5700, 0.9140, 0.2904, 0.3008, 0.0592, 0.5360, 0.1212, 0.2880,\n",
      "        0.4150, 0.8034])\n"
     ]
    }
   ],
   "source": [
    "result = result / M\n",
    "print(result[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23936\\3575953207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "result.requires_grad(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d372851e929683907f22a981204426c4d48f24f5c1f70c60438207dfe1ba0b7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('py37@pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
